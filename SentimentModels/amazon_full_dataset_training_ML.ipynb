{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\OneDrive - National University of Singapore\\EBA5004\\project\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import nltk\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #as vectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "##########################################################################3\n",
    "##prepare dataset\n",
    "from os import getcwd, chdir\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "fpath = getcwd()\n",
    "print (fpath)\n",
    "# Change your path here\n",
    "chdir(fpath) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AMAZON_FASHION.npy', 'rb') as f:\n",
    "    a = np.load(f, allow_pickle=True)\n",
    "df_data=pd.DataFrame(a,columns=['asin', 'overall', 'reviewText', 'reviewTime', 'reviewerID',\n",
    "       'reviewerName', 'summary', 'unixReviewTime', 'verified', 'vote',\n",
    "       'style', 'image'\n",
    "])\n",
    "subset_data=df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactly what I needed.</td>\n",
       "      <td>10 20, 2014</td>\n",
       "      <td>A1D4G1SNUZWQOT</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>perfect replacements!!</td>\n",
       "      <td>1.41376e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>2</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>09 28, 2014</td>\n",
       "      <td>A3DDWDH9PX2YX2</td>\n",
       "      <td>Sonja Lau</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>1.41186e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>4</td>\n",
       "      <td>Love these... I am going to order another pack...</td>\n",
       "      <td>08 25, 2014</td>\n",
       "      <td>A2MWC41EW7XL15</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>My New 'Friends' !!</td>\n",
       "      <td>1.40892e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>2</td>\n",
       "      <td>too tiny an opening</td>\n",
       "      <td>08 24, 2014</td>\n",
       "      <td>A2UH2QQ275NV45</td>\n",
       "      <td>Jodi Stoner</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1.40884e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>3</td>\n",
       "      <td>Okay</td>\n",
       "      <td>07 27, 2014</td>\n",
       "      <td>A89F3LQADZBS5</td>\n",
       "      <td>Alexander D.</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1.40642e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883631</th>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love this dress!!  It's sexy and ...</td>\n",
       "      <td>02 21, 2017</td>\n",
       "      <td>A1ZSB2Q144UTEY</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>I absolutely love this dress</td>\n",
       "      <td>1.48764e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883632</th>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm 5'6 175lbs. I'm on the tall side. I wear a...</td>\n",
       "      <td>11 25, 2016</td>\n",
       "      <td>A2CCDV0J5VB6F2</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>I wear a large and ordered a large and it stil...</td>\n",
       "      <td>1.48003e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883633</th>\n",
       "      <td>B01HJHTH5U</td>\n",
       "      <td>3</td>\n",
       "      <td>Too big in the chest area!</td>\n",
       "      <td>11 10, 2016</td>\n",
       "      <td>A3O90PACS7B61K</td>\n",
       "      <td>Fabfifty</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1.47874e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883634</th>\n",
       "      <td>B01HJHF97K</td>\n",
       "      <td>3</td>\n",
       "      <td>Too clear in the back, needs lining</td>\n",
       "      <td>11 10, 2016</td>\n",
       "      <td>A2HO94I89U3LNH</td>\n",
       "      <td>Mgomez</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1.47874e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883635</th>\n",
       "      <td>B01HJG5NMW</td>\n",
       "      <td>5</td>\n",
       "      <td>Ordered and was slightly small. Worked with th...</td>\n",
       "      <td>08 9, 2016</td>\n",
       "      <td>A2RSX9E79DUHRX</td>\n",
       "      <td>Natasha Mascarenhas</td>\n",
       "      <td>The quality is excellent and it is so cute</td>\n",
       "      <td>1.4707e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>883636 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin overall                                         reviewText  \\\n",
       "0       7106116521       5                             Exactly what I needed.   \n",
       "1       7106116521       2  I agree with the other review, the opening is ...   \n",
       "2       7106116521       4  Love these... I am going to order another pack...   \n",
       "3       7106116521       2                                too tiny an opening   \n",
       "4       7106116521       3                                               Okay   \n",
       "...            ...     ...                                                ...   \n",
       "883631  B01HJHTH5U       5  I absolutely love this dress!!  It's sexy and ...   \n",
       "883632  B01HJHTH5U       5  I'm 5'6 175lbs. I'm on the tall side. I wear a...   \n",
       "883633  B01HJHTH5U       3                         Too big in the chest area!   \n",
       "883634  B01HJHF97K       3                Too clear in the back, needs lining   \n",
       "883635  B01HJG5NMW       5  Ordered and was slightly small. Worked with th...   \n",
       "\n",
       "         reviewTime      reviewerID         reviewerName  \\\n",
       "0       10 20, 2014  A1D4G1SNUZWQOT                Tracy   \n",
       "1       09 28, 2014  A3DDWDH9PX2YX2            Sonja Lau   \n",
       "2       08 25, 2014  A2MWC41EW7XL15             Kathleen   \n",
       "3       08 24, 2014  A2UH2QQ275NV45          Jodi Stoner   \n",
       "4       07 27, 2014   A89F3LQADZBS5         Alexander D.   \n",
       "...             ...             ...                  ...   \n",
       "883631  02 21, 2017  A1ZSB2Q144UTEY      Amazon Customer   \n",
       "883632  11 25, 2016  A2CCDV0J5VB6F2      Amazon Customer   \n",
       "883633  11 10, 2016  A3O90PACS7B61K             Fabfifty   \n",
       "883634  11 10, 2016  A2HO94I89U3LNH               Mgomez   \n",
       "883635   08 9, 2016  A2RSX9E79DUHRX  Natasha Mascarenhas   \n",
       "\n",
       "                                                  summary unixReviewTime  \\\n",
       "0                                  perfect replacements!!    1.41376e+09   \n",
       "1       I agree with the other review, the opening is ...    1.41186e+09   \n",
       "2                                     My New 'Friends' !!    1.40892e+09   \n",
       "3                                               Two Stars    1.40884e+09   \n",
       "4                                             Three Stars    1.40642e+09   \n",
       "...                                                   ...            ...   \n",
       "883631                       I absolutely love this dress    1.48764e+09   \n",
       "883632  I wear a large and ordered a large and it stil...    1.48003e+09   \n",
       "883633                                        Three Stars    1.47874e+09   \n",
       "883634                                        Three Stars    1.47874e+09   \n",
       "883635         The quality is excellent and it is so cute     1.4707e+09   \n",
       "\n",
       "       verified vote style image  \n",
       "0             1  NaN   NaN   NaN  \n",
       "1             1    3   NaN   NaN  \n",
       "2             0  NaN   NaN   NaN  \n",
       "3             1  NaN   NaN   NaN  \n",
       "4             0  NaN   NaN   NaN  \n",
       "...         ...  ...   ...   ...  \n",
       "883631        1  NaN   NaN   NaN  \n",
       "883632        1    2   NaN   NaN  \n",
       "883633        1  NaN   NaN   NaN  \n",
       "883634        1  NaN   NaN   NaN  \n",
       "883635        1  NaN   NaN   NaN  \n",
       "\n",
       "[883636 rows x 12 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              asin overall                                         reviewText  \\\n",
      "0       7106116521       5                             Exactly what I needed.   \n",
      "1       7106116521       2  I agree with the other review, the opening is ...   \n",
      "2       7106116521       4  Love these... I am going to order another pack...   \n",
      "3       7106116521       2                                too tiny an opening   \n",
      "4       7106116521       3                                               Okay   \n",
      "...            ...     ...                                                ...   \n",
      "883631  B01HJHTH5U       5  I absolutely love this dress!!  It's sexy and ...   \n",
      "883632  B01HJHTH5U       5  I'm 5'6 175lbs. I'm on the tall side. I wear a...   \n",
      "883633  B01HJHTH5U       3                         Too big in the chest area!   \n",
      "883634  B01HJHF97K       3                Too clear in the back, needs lining   \n",
      "883635  B01HJG5NMW       5  Ordered and was slightly small. Worked with th...   \n",
      "\n",
      "         reviewTime      reviewerID         reviewerName  \\\n",
      "0       10 20, 2014  A1D4G1SNUZWQOT                Tracy   \n",
      "1       09 28, 2014  A3DDWDH9PX2YX2            Sonja Lau   \n",
      "2       08 25, 2014  A2MWC41EW7XL15             Kathleen   \n",
      "3       08 24, 2014  A2UH2QQ275NV45          Jodi Stoner   \n",
      "4       07 27, 2014   A89F3LQADZBS5         Alexander D.   \n",
      "...             ...             ...                  ...   \n",
      "883631  02 21, 2017  A1ZSB2Q144UTEY      Amazon Customer   \n",
      "883632  11 25, 2016  A2CCDV0J5VB6F2      Amazon Customer   \n",
      "883633  11 10, 2016  A3O90PACS7B61K             Fabfifty   \n",
      "883634  11 10, 2016  A2HO94I89U3LNH               Mgomez   \n",
      "883635   08 9, 2016  A2RSX9E79DUHRX  Natasha Mascarenhas   \n",
      "\n",
      "                                                  summary unixReviewTime  \\\n",
      "0                                  perfect replacements!!    1.41376e+09   \n",
      "1       I agree with the other review, the opening is ...    1.41186e+09   \n",
      "2                                     My New 'Friends' !!    1.40892e+09   \n",
      "3                                               Two Stars    1.40884e+09   \n",
      "4                                             Three Stars    1.40642e+09   \n",
      "...                                                   ...            ...   \n",
      "883631                       I absolutely love this dress    1.48764e+09   \n",
      "883632  I wear a large and ordered a large and it stil...    1.48003e+09   \n",
      "883633                                        Three Stars    1.47874e+09   \n",
      "883634                                        Three Stars    1.47874e+09   \n",
      "883635         The quality is excellent and it is so cute     1.4707e+09   \n",
      "\n",
      "       verified vote style image  equal_or_lower_than_3?  \n",
      "0             1  NaN   NaN   NaN                     1.0  \n",
      "1             1    3   NaN   NaN                    -1.0  \n",
      "2             0  NaN   NaN   NaN                     1.0  \n",
      "3             1  NaN   NaN   NaN                    -1.0  \n",
      "4             0  NaN   NaN   NaN                    -1.0  \n",
      "...         ...  ...   ...   ...                     ...  \n",
      "883631        1  NaN   NaN   NaN                     1.0  \n",
      "883632        1    2   NaN   NaN                     1.0  \n",
      "883633        1  NaN   NaN   NaN                    -1.0  \n",
      "883634        1  NaN   NaN   NaN                    -1.0  \n",
      "883635        1  NaN   NaN   NaN                     1.0  \n",
      "\n",
      "[883636 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "subset_data.loc[subset_data['overall'] <= 3, 'equal_or_lower_than_3?'] = -1\n",
    "subset_data.loc[subset_data['overall'] > 3, 'equal_or_lower_than_3?'] = 1 \n",
    "\n",
    "print (subset_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883636"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=subset_data['reviewText'].apply(str).tolist()\n",
    "Y=subset_data['equal_or_lower_than_3?'].tolist()\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[:int(len(Y)*0.8)]\n",
    "X_test=X[int(len(Y)*0.8):]\n",
    "Y_train=Y[:int(len(Y)*0.8)]\n",
    "Y_test=Y[int(len(Y)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706908"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176728"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176728, 1715877)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorizer the sentences using Tfidf vale\n",
    "#Make sure test data should be transformed using vectorizer learned from trainning data \n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1)#unigram and bigram\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "# same feature set\n",
    "\n",
    "test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(706908, 1715877)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34174  28924]\n",
      " [  1641 111989]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.54      0.69     63098\n",
      "         1.0       0.79      0.99      0.88    113630\n",
      "\n",
      "    accuracy                           0.83    176728\n",
      "   macro avg       0.87      0.76      0.79    176728\n",
      "weighted avg       0.85      0.83      0.81    176728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#Apply NB model\n",
    "clf_NB = MultinomialNB().fit(train_vectors, Y_train)\n",
    "predNB = clf_NB.predict(test_vectors)\n",
    "pred = list(predNB)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "errors=[]\n",
    "for a,b, index in pred,Y_test:\n",
    "    if a==b:\n",
    "        continue\n",
    "    else:\n",
    "        errors.append(test_set[index])\n",
    "print (errors)    \n",
    "'''\n",
    "\n",
    "print(metrics.confusion_matrix(Y_test, pred))\n",
    "print(metrics.classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53542   9556]\n",
      " [  6697 106933]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.89      0.85      0.87     63098\n",
      "         1.0       0.92      0.94      0.93    113630\n",
      "\n",
      "    accuracy                           0.91    176728\n",
      "   macro avg       0.90      0.89      0.90    176728\n",
      "weighted avg       0.91      0.91      0.91    176728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "# MaxEnt = LogisticRegression\n",
    "clf_ME = LogisticRegression(random_state=0, solver='lbfgs').fit(train_vectors, Y_train)\n",
    "predME = clf_ME.predict(test_vectors)\n",
    "pred = list(predME)\n",
    "print(metrics.confusion_matrix(Y_test, pred))\n",
    "print(metrics.classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 45434  17664]\n",
      " [ 10995 102635]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.81      0.72      0.76     63098\n",
      "         1.0       0.85      0.90      0.88    113630\n",
      "\n",
      "    accuracy                           0.84    176728\n",
      "   macro avg       0.83      0.81      0.82    176728\n",
      "weighted avg       0.84      0.84      0.84    176728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####KNN Classifier\n",
    "def train_knn(X, y, k, weight):\n",
    "    \"\"\"\n",
    "    Create and train the k-nearest neighbor.\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors = k, weights = weight, metric = 'cosine', algorithm = 'brute')\n",
    "    knn.fit(X, y)\n",
    "    return knn\n",
    "\n",
    "\n",
    "kn = train_knn(train_vectors, Y_train, 3, 'distance')# distance weights - by inverse of distance\n",
    "predKN = kn.predict(test_vectors)\n",
    "pred = list(predKN)\n",
    "print(metrics.confusion_matrix(Y_test, pred))\n",
    "print(metrics.classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50151  12947]\n",
      " [ 11289 102341]]\n",
      "0.8628627042687067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.82      0.79      0.81     63098\n",
      "         1.0       0.89      0.90      0.89    113630\n",
      "\n",
      "    accuracy                           0.86    176728\n",
      "   macro avg       0.85      0.85      0.85    176728\n",
      "weighted avg       0.86      0.86      0.86    176728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Apply SVM model\n",
    "'''\n",
    "Not all the feature points are needed to define the support vector.\n",
    "In a way only the most informative feature points help to define the support vector which makes the SVM ideal for high-dimensional classification \n",
    "and sparse matrics common in NLP. \n",
    "The SVM can also work on feature points that are not linearly separable through kernel transformation of the feature points.\n",
    "0.85 ACC\n",
    "0.85 F1\n",
    "'''\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model_svm = LinearSVC(C=100)\n",
    "clr_svm = model_svm.fit(train_vectors, Y_train)\n",
    "\n",
    "\n",
    "predicted = clr_svm.predict(test_vectors)\n",
    " \n",
    "print(metrics.confusion_matrix(Y_test, predicted))\n",
    "print(np.mean(predicted == Y_test) )\n",
    "print(metrics.classification_report(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1649230)\t0.5849470830192129\n",
      "  (0, 493533)\t0.46348302998369445\n",
      "  (0, 958650)\t0.4389468387803993\n",
      "  (0, 1648362)\t0.3102000709766462\n",
      "  (0, 493166)\t0.39258372314096995\n",
      "  (1, 1262837)\t0.13652022915556866\n",
      "  (1, 985887)\t0.16969047125028697\n",
      "  (1, 1138200)\t0.13878650433698658\n",
      "  (1, 1462343)\t0.06503450582147204\n",
      "  (1, 568424)\t0.059504964460325334\n",
      "  (1, 257551)\t0.0980048122072092\n",
      "  (1, 62082)\t0.12965521522167392\n",
      "  (1, 262958)\t0.09619367395398801\n",
      "  (1, 982235)\t0.10142658663857318\n",
      "  (1, 1691421)\t0.08968223011003797\n",
      "  (1, 1259621)\t0.1937734191020609\n",
      "  (1, 985876)\t0.14917367381253127\n",
      "  (1, 1178471)\t0.11460997850692153\n",
      "  (1, 1482723)\t0.08340972471996141\n",
      "  (1, 1341074)\t0.10104958965843636\n",
      "  (1, 475883)\t0.16402910230230255\n",
      "  (1, 1455414)\t0.10516197995525187\n",
      "  (1, 784991)\t0.0984719959851576\n",
      "  (1, 1442052)\t0.1372599971474804\n",
      "  (1, 685041)\t0.1316634327204454\n",
      "  :\t:\n",
      "  (706906, 997989)\t0.07985617508355757\n",
      "  (706906, 1470583)\t0.04965198378094799\n",
      "  (706906, 561182)\t0.03423582896393911\n",
      "  (706906, 1481241)\t0.04523680793400715\n",
      "  (706906, 747323)\t0.06887087037917797\n",
      "  (706906, 1449778)\t0.10595585610606768\n",
      "  (706907, 138213)\t0.3726920562300373\n",
      "  (706907, 91071)\t0.3726920562300373\n",
      "  (706907, 138212)\t0.3726920562300373\n",
      "  (706907, 587409)\t0.305463694743066\n",
      "  (706907, 1501697)\t0.3147932447564402\n",
      "  (706907, 568493)\t0.2470395331137609\n",
      "  (706907, 1139509)\t0.2564303621633364\n",
      "  (706907, 384699)\t0.14333272398118713\n",
      "  (706907, 783619)\t0.1844205857241528\n",
      "  (706907, 844749)\t0.24443730755226092\n",
      "  (706907, 1139467)\t0.2096641630112195\n",
      "  (706907, 384595)\t0.09667370480550244\n",
      "  (706907, 587252)\t0.15974655173219227\n",
      "  (706907, 1101055)\t0.14584075434448365\n",
      "  (706907, 1501244)\t0.16330614702484034\n",
      "  (706907, 89853)\t0.04755955700227978\n",
      "  (706907, 842221)\t0.09620667148309844\n",
      "  (706907, 561182)\t0.060717570113982884\n",
      "  (706907, 781978)\t0.0885587256313634\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(706908, 15000)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################\n",
    "##Select K Best features\n",
    "\n",
    "ch21 = SelectKBest(chi2, k=15000)\n",
    "# Transform your training and testing datasets accordingly\n",
    "train_Kbest = ch21.fit_transform(train_vectors, Y_train)\n",
    "test_Kbest = ch21.transform(test_vectors)\n",
    "train_Kbest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53014  10084]\n",
      " [  6960 106670]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.88      0.84      0.86     63098\n",
      "         1.0       0.91      0.94      0.93    113630\n",
      "\n",
      "    accuracy                           0.90    176728\n",
      "   macro avg       0.90      0.89      0.89    176728\n",
      "weighted avg       0.90      0.90      0.90    176728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Re-Train ME model\n",
    "clf_ME = LogisticRegression(random_state=0, solver='lbfgs').fit(train_Kbest, Y_train)\n",
    "predME = clf_ME.predict(test_Kbest)\n",
    "pred = list(predME)\n",
    "print(metrics.confusion_matrix(Y_test, pred))\n",
    "print(metrics.classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(706908, 1715877)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
