{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip,json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AMAZON_FASHION.npy', 'rb') as f:\n",
    "    a = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactly what I needed.</td>\n",
       "      <td>10 20, 2014</td>\n",
       "      <td>A1D4G1SNUZWQOT</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>perfect replacements!!</td>\n",
       "      <td>1.41376e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>2</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>09 28, 2014</td>\n",
       "      <td>A3DDWDH9PX2YX2</td>\n",
       "      <td>Sonja Lau</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>1.41186e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>4</td>\n",
       "      <td>Love these... I am going to order another pack...</td>\n",
       "      <td>08 25, 2014</td>\n",
       "      <td>A2MWC41EW7XL15</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>My New 'Friends' !!</td>\n",
       "      <td>1.40892e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>2</td>\n",
       "      <td>too tiny an opening</td>\n",
       "      <td>08 24, 2014</td>\n",
       "      <td>A2UH2QQ275NV45</td>\n",
       "      <td>Jodi Stoner</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1.40884e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7106116521</td>\n",
       "      <td>3</td>\n",
       "      <td>Okay</td>\n",
       "      <td>07 27, 2014</td>\n",
       "      <td>A89F3LQADZBS5</td>\n",
       "      <td>Alexander D.</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1.40642e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin overall                                         reviewText  \\\n",
       "0  7106116521       5                             Exactly what I needed.   \n",
       "1  7106116521       2  I agree with the other review, the opening is ...   \n",
       "2  7106116521       4  Love these... I am going to order another pack...   \n",
       "3  7106116521       2                                too tiny an opening   \n",
       "4  7106116521       3                                               Okay   \n",
       "\n",
       "    reviewTime      reviewerID  reviewerName  \\\n",
       "0  10 20, 2014  A1D4G1SNUZWQOT         Tracy   \n",
       "1  09 28, 2014  A3DDWDH9PX2YX2     Sonja Lau   \n",
       "2  08 25, 2014  A2MWC41EW7XL15      Kathleen   \n",
       "3  08 24, 2014  A2UH2QQ275NV45   Jodi Stoner   \n",
       "4  07 27, 2014   A89F3LQADZBS5  Alexander D.   \n",
       "\n",
       "                                             summary unixReviewTime verified  \\\n",
       "0                             perfect replacements!!    1.41376e+09        1   \n",
       "1  I agree with the other review, the opening is ...    1.41186e+09        1   \n",
       "2                                My New 'Friends' !!    1.40892e+09        0   \n",
       "3                                          Two Stars    1.40884e+09        1   \n",
       "4                                        Three Stars    1.40642e+09        0   \n",
       "\n",
       "  vote style image  \n",
       "0  NaN   NaN   NaN  \n",
       "1    3   NaN   NaN  \n",
       "2  NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN  \n",
       "4  NaN   NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data=pd.DataFrame(a,columns=['asin', 'overall', 'reviewText', 'reviewTime', 'reviewerID',\n",
    "       'reviewerName', 'summary', 'unixReviewTime', 'verified', 'vote',\n",
    "       'style', 'image'\n",
    "])\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataHandler(df,row):\n",
    "    return (str(df['reviewText'].iloc[row]),{'cats': {'neg': (3-int(df['overall'].iloc[row]))/3, 'pos': (int(df['overall'].iloc[row])-3)/3}})\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "def load_training_data(df,split):\n",
    "    # Load from files\n",
    "    df = shuffle(df)\n",
    "    datas=[]\n",
    "    for i in range(len(df)):\n",
    "        datas.append(dataHandler(df_data,i))\n",
    "\n",
    "    split = int(len(datas) * split)\n",
    "    return datas[:split], datas[split:]\n",
    "\n",
    "training_data, testing_data =load_training_data(df_data,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "def train_model(\n",
    "    training_data: list,\n",
    "    test_data: list,\n",
    "    iterations: int = 20\n",
    ") -> None:\n",
    "    # Build pipeline\n",
    "    nlp = spacy.load(\"en\") # Change this for loading medium or large models\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\", config={\"architecture\": \"simple_cnn\"}\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "    textcat.add_label(\"pos\")\n",
    "    textcat.add_label(\"neg\")\n",
    "\n",
    "    # Train only textcat\n",
    "    training_excluded_pipes = [\n",
    "        pipe for pipe in nlp.pipe_names if pipe != \"textcat\"\n",
    "    ]\n",
    "    with nlp.disable_pipes(training_excluded_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        # Training loop\n",
    "        print(\"Beginning training\")\n",
    "        print(\"Loss\\tPrecision\\tRecall\\tF-score\")\n",
    "        batch_sizes = compounding(\n",
    "            4.0, 32.0, 1.001\n",
    "        )  # A generator that yields infinite series of input numbers\n",
    "        for i in range(iterations):\n",
    "            print(f\"Training iteration {i}\")\n",
    "            loss = {}\n",
    "            random.shuffle(training_data)\n",
    "            batches = minibatch(training_data, size=batch_sizes)\n",
    "            for batch in batches:\n",
    "                text, labels = zip(*batch)\n",
    "                nlp.update(text, labels, drop=0.2, sgd=optimizer, losses=loss)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                evaluation_results = evaluate_model(\n",
    "                    tokenizer=nlp.tokenizer,\n",
    "                    textcat=textcat,\n",
    "                    test_data=test_data\n",
    "                )\n",
    "                print(\n",
    "                    f\"{loss['textcat']}\\t{evaluation_results['precision']}\"\n",
    "                    f\"\\t{evaluation_results['recall']}\"\n",
    "                    f\"\\t{evaluation_results['f-score']}\"\n",
    "                )\n",
    "\n",
    "    # Save model\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(\"model_artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    tokenizer, textcat, test_data: list\n",
    ") -> dict:\n",
    "    reviews, labels = zip(*test_data)\n",
    "    reviews = (tokenizer(review) for review in reviews)\n",
    "    true_positives = 0\n",
    "    false_positives = 1e-8  # Can't be 0 because of presence in denominator\n",
    "    true_negatives = 0\n",
    "    false_negatives = 1e-8\n",
    "    for i, review in enumerate(textcat.pipe(reviews)):\n",
    "        true_label = labels[i]['cats']\n",
    "        for predicted_label, score in review.cats.items():\n",
    "            # Every cats dictionary includes both labels. You can get all\n",
    "            # the info you need with just the pos label.\n",
    "            if (\n",
    "                predicted_label == \"neg\"\n",
    "            ):\n",
    "                continue\n",
    "            if score >= 0.5 and true_label[\"pos\"]:\n",
    "                true_positives += 1\n",
    "            elif score >= 0.5 and true_label[\"neg\"]:\n",
    "                false_positives += 1\n",
    "            elif score < 0.5 and true_label[\"neg\"]:\n",
    "                true_negatives += 1\n",
    "            elif score < 0.5 and true_label[\"pos\"]:\n",
    "                false_negatives += 1\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        f_score = 0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f-score\": f_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Loss\tPrecision\tRecall\tF-score\n",
      "Training iteration 0\n",
      "30.07132751822064\t0.9999999999998764\t0.9999999999998764\t0.9999999999998764\n",
      "Training iteration 1\n",
      "8.248354661598569\t0.9999999999998772\t0.9999999999998772\t0.9999999999998772\n",
      "Training iteration 2\n",
      "8.194442044317839\t0.9999999999998792\t0.9999999999998792\t0.9999999999998792\n",
      "Training iteration 3\n",
      "8.168050613559899\t0.9999999999998783\t0.9999999999998783\t0.9999999999998783\n",
      "Training iteration 4\n",
      "8.152934108133195\t0.9999999999998777\t0.9999999999998777\t0.9999999999998777\n",
      "Training iteration 5\n",
      "8.142768362420611\t0.9999999999998769\t0.9999999999998769\t0.9999999999998769\n",
      "Training iteration 6\n",
      "8.136201839210116\t0.9999999999998763\t0.9999999999998763\t0.9999999999998763\n",
      "Training iteration 7\n",
      "8.132240991064464\t0.9999999999998753\t0.9999999999998753\t0.9999999999998753\n",
      "Training iteration 8\n",
      "8.128194896766217\t0.9999999999998759\t0.9999999999998759\t0.9999999999998759\n",
      "Training iteration 9\n",
      "8.127085898100631\t0.9999999999998755\t0.9999999999998755\t0.9999999999998755\n",
      "Training iteration 10\n",
      "8.122576117777498\t0.9999999999998758\t0.9999999999998758\t0.9999999999998758\n",
      "Training iteration 11\n",
      "8.121753194907797\t0.9999999999998761\t0.9999999999998761\t0.9999999999998761\n"
     ]
    }
   ],
   "source": [
    "train_model(training_data, testing_data, 12)#<--pls uncomment if need to do training\n",
    "#from IPython.display import Image \n",
    "#pil_img = Image(filename='training_steps.jpeg')\n",
    "#display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review text: Exactly what I needed\n",
      "Predicted sentiment: Positive\tScore: 0.6154553294181824\n",
      "overall:4.846365988254547\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "loaded_model = spacy.load(\"model_artifacts\") \n",
    "TEST_REVIEW = \"Exactly what I needed\"\n",
    "\n",
    "# Test predictions for reviews\n",
    "def test_model(input_data: str = TEST_REVIEW):\n",
    "    #  Load saved trained model\n",
    "    loaded_model = spacy.load(\"model_artifacts\")\n",
    "    # Generate prediction\n",
    "    parsed_text = loaded_model(input_data)\n",
    "    # Determine prediction to return\n",
    "    if parsed_text.cats[\"pos\"] > parsed_text.cats[\"neg\"]:\n",
    "        prediction = \"Positive\"\n",
    "        score = parsed_text.cats[\"pos\"]\n",
    "        overall =score*3+3\n",
    "    else:\n",
    "        prediction = \"Negative\"\n",
    "        score = parsed_text.cats[\"neg\"]\n",
    "        overall =3-score*3\n",
    "    print(f\"Review text: {input_data}\\nPredicted sentiment: {prediction}\"\n",
    "        f\"\\tScore: {score}\")\n",
    "    \n",
    "    print('overall:%s'%overall)\n",
    "    \n",
    "test_model(TEST_REVIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
